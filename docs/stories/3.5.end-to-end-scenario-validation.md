# Story 3.5: End-to-End Scenario Validation (Optional Documentation)

## Status
Done

## Story

**As a** user,
**I want** to prepare demonstration materials and document real-world usage scenarios,
**so that** potential users can understand the value of tmdb-mcp in practical contexts.

**注意**: 此 Story 为**可选**,主要用于准备演示材料和用户文档,**不作为 Epic 3 完成的阻塞条件**。技术验证已由 Story 1.7 和 3.4 的自动化测试完成。

## Acceptance Criteria

1. 使用 Claude Code 执行 4 个核心场景:智能文件重命名、片荒推荐、关联探索、智能推荐
2. 额外组合场景:热门内容探索 + 详情查看、发现 + 推荐链条
3. 性能验证:每个场景端到端响应时间(包括 LLM 推理)< 10 秒,复杂场景 < 15 秒
4. 用户体验验证:Claude 的回复是否自然有用、工具选择是否准确、返回数据是否满足需求
5. 错误恢复验证:故意提供模糊或错误输入,验证 Claude 能够引导用户
6. 测试结果文档:记录截图/日志到 `.ai/epic3-e2e-scenarios.md`,记录用户体验评分
7. 问题修复:记录所有问题、修复阻塞性问题
8. 交付物:演示材料(截图/录屏)记录到 `.ai/epic3-e2e-scenarios.md`,用于 Epic 5 文档和社区宣传

## Tasks / Subtasks

- [ ] Task 1: 环境准备和配置验证 (AC: 1, 2)
  - [ ] 确认 TMDB MCP 服务已编译并可运行
  - [ ] 确认 Claude Code 已正确配置 tmdb-mcp 服务
  - [ ] 验证 TMDB API Key 有效
  - [ ] 测试基础连接:运行简单的 search 查询验证服务正常
  - [ ] 准备测试用例数据:确定要搜索的电影名、ID 等

- [ ] Task 2: 执行 4 个核心场景测试 (AC: 1, 3, 4)
  - [ ] **场景 1: 智能文件重命名**
    - [ ] 用户提示:"帮我查询电影 'Inception' 的详细信息,用于文件重命名"
    - [ ] 记录 Claude 的工具调用顺序(search → get_details)
    - [ ] 验证返回数据包含:标题、年份、导演、主演
    - [ ] 记录端到端响应时间
    - [ ] 截图 Claude 的回复和建议的文件名格式
  - [ ] **场景 2: 片荒推荐**
    - [ ] 用户提示:"推荐一些最近热门的科幻电影"
    - [ ] 记录 Claude 的工具调用(get_trending 或 discover_movies)
    - [ ] 验证返回至少 5 部电影,包含评分和简介
    - [ ] 记录响应时间
    - [ ] 截图推荐列表和 Claude 的解释
  - [ ] **场景 3: 关联探索**
    - [ ] 用户提示:"找一些类似《盗梦空间》的电影"
    - [ ] 记录 Claude 的工具调用(search → get_recommendations 或 discover_movies)
    - [ ] 验证推荐电影与原电影风格相似
    - [ ] 记录响应时间
    - [ ] 截图推荐结果
  - [ ] **场景 4: 智能推荐**
    - [ ] 用户提示:"我喜欢诺兰的电影,推荐一些类似风格的作品"
    - [ ] 记录 Claude 的工具调用链(可能是 search person → discover + filters)
    - [ ] 验证推荐合理性
    - [ ] 记录响应时间
    - [ ] 截图完整对话

- [ ] Task 3: 执行额外组合场景 (AC: 2, 3, 4)
  - [ ] **场景 5: 热门内容探索 + 详情查看**
    - [ ] 用户提示:"本周最热门的电视剧是什么?给我详细介绍第一部"
    - [ ] 记录工具调用(get_trending → get_details)
    - [ ] 验证详情完整性(演员表、集数信息等)
    - [ ] 记录响应时间
  - [ ] **场景 6: 发现 + 推荐链条**
    - [ ] 用户提示:"找一部 2020 年后的高分动作片,然后推荐类似的电影"
    - [ ] 记录工具调用链(discover_movies → get_recommendations)
    - [ ] 验证推荐链条的连贯性
    - [ ] 记录响应时间

- [ ] Task 4: 性能验证和记录 (AC: 3)
  - [ ] 记录每个场景的端到端响应时间(包括 LLM 推理)
  - [ ] 验证简单场景 < 10 秒
  - [ ] 验证复杂场景 < 15 秒
  - [ ] 记录超时场景(如有),分析原因
  - [ ] 创建性能表格记录到文档

- [ ] Task 5: 用户体验验证 (AC: 4)
  - [ ] 对每个场景进行用户体验评分(1-5 分):
    - [ ] Claude 回复是否自然有用
    - [ ] 工具选择是否准确
    - [ ] 返回数据是否满足需求
    - [ ] 整体用户体验
  - [ ] 记录用户体验亮点和痛点
  - [ ] 记录改进建议

- [ ] Task 6: 错误恢复验证 (AC: 5)
  - [ ] 测试模糊输入:"找一部电影,名字我忘了,好像是诺兰导演的"
  - [ ] 测试错误输入:"查询电影 ID 999999999 的详情"
  - [ ] 测试无结果场景:"推荐 1800 年的科幻片"
  - [ ] 验证 Claude 是否能够:
    - [ ] 引导用户提供更多信息
    - [ ] 友好地处理错误情况
    - [ ] 提供替代方案
  - [ ] 记录错误处理质量评分

- [ ] Task 7: 创建测试结果文档 (AC: 6, 8)
  - [ ] 创建 `.ai/epic3-e2e-scenarios.md` 文件
  - [ ] 记录测试环境信息:Go 版本、OS、Claude Code 版本、TMDB API Key 状态
  - [ ] 记录每个场景的详细结果:
    - [ ] 用户提示
    - [ ] Claude 的工具调用序列
    - [ ] 响应时间
    - [ ] 用户体验评分
    - [ ] 截图或日志片段
  - [ ] 记录性能验证结果表格
  - [ ] 记录用户体验总结
  - [ ] 记录错误恢复测试结果
  - [ ] 添加演示材料(截图/录屏)
  - [ ] 总结测试结论和改进建议

- [ ] Task 8: 问题识别和修复 (AC: 7)
  - [ ] 整理测试中发现的所有问题
  - [ ] 对问题进行优先级分类:
    - [ ] 阻塞性问题(必须修复)
    - [ ] 严重问题(应该修复)
    - [ ] 轻微问题(可选修复)
    - [ ] 改进建议(未来增强)
  - [ ] 修复所有阻塞性问题
  - [ ] 记录问题和修复到文档

## Dev Notes

### 前一个故事的重要洞察

从 Story 3.4 (Comprehensive Integration Testing) 获取的关键信息:

**自动化测试已完成**:
- ✅ 所有 6 个工具的自动化集成测试通过(28+ 测试用例)
- ✅ 多工具组合测试成功(3 个场景)
- ✅ 性能测试通过:总耗时 2.34s(< 10s 要求)
- ✅ 并发测试通过:无数据竞争,速率限制正确工作
- ✅ 错误场景测试全面
- ✅ 测试覆盖率 87.5%(超出 70% 目标)

**本故事的重点**:
- **非阻塞**: 此 Story 为可选,技术验证已完成
- **文档导向**: 主要目标是准备演示材料和用户文档
- **用户体验**: 关注真实 Claude Code 环境下的用户体验
- **社区准备**: 为 Epic 5 的文档和社区宣传准备素材

[Source: docs/stories/3.4.comprehensive-integration-testing.md#Dev Agent Record]

### 项目源码树结构

**相关文件位置**:
```
.ai/
└── epic3-e2e-scenarios.md        # 新增:端到端场景测试结果文档

docs/stories/
└── 3.5.end-to-end-scenario-validation.md  # 本故事文件

cmd/tmdb-mcp/
└── main.go                        # MCP 服务入口

examples/
└── claude-code-config.json        # Claude Code 配置示例(Epic 5 创建)
```

**测试环境要求**:
- 编译后的 `tmdb-mcp` 二进制文件
- 有效的 TMDB API Key
- Claude Code 客户端(配置了 tmdb-mcp 服务)
- 截图/录屏工具(可选)

[Source: docs/architecture/source-tree.md]

### 核心场景说明

**场景 1: 智能文件重命名**
- **使用场景**: 用户有下载的电影文件 `movie.2010.mkv`,需要重命名为 `Inception.2010.Christopher.Nolan.mkv`
- **工具链**: `search` → `get_details`
- **关键数据**: 标题(Inception)、年份(2010)、导演(Christopher Nolan)
- **用户价值**: 自动化媒体库管理

**场景 2: 片荒推荐**
- **使用场景**: 用户不知道看什么电影
- **工具**: `get_trending` 或 `discover_movies`
- **关键数据**: 热门电影列表、评分、简介
- **用户价值**: 快速发现优质内容

**场景 3: 关联探索**
- **使用场景**: 用户喜欢某部电影,想找类似的
- **工具链**: `search` → `get_recommendations` 或 `discover_movies` with filters
- **关键数据**: 相似电影列表
- **用户价值**: 扩展观影范围

**场景 4: 智能推荐**
- **使用场景**: 用户喜欢某位导演的风格,想找类似作品
- **工具链**: `search` (person) → `discover_movies` with genre filters
- **关键数据**: 导演作品列表、相似风格电影
- **用户价值**: 基于创作者的深度探索

[Source: docs/prd/epic-details.md#Story 3.5]

### 性能和用户体验标准

**性能要求**:
- 简单场景(单工具调用):端到端 < 10 秒
- 复杂场景(多工具调用):端到端 < 15 秒
- 端到端时间包括:用户输入 → Claude 推理 → 工具调用 → TMDB API → 返回 → Claude 生成回复

**用户体验评分标准**:
- **5 分**: 完美体验,Claude 完全理解意图,工具选择准确,回复有用自然
- **4 分**: 良好体验,可能需要一次澄清,结果满意
- **3 分**: 可接受体验,需要多次交互才能得到满意结果
- **2 分**: 较差体验,Claude 工具选择不当或回复不准确
- **1 分**: 糟糕体验,无法完成任务

**错误处理质量标准**:
- Claude 应该友好地处理错误(404、无结果等)
- Claude 应该能够引导用户提供更多信息
- Claude 应该提供替代方案或建议

[Source: docs/prd/epic-details.md#Story 3.5 Acceptance Criteria]

### 文档模板参考

`.ai/epic3-e2e-scenarios.md` 文档结构:

```markdown
# Epic 3 End-to-End Scenario Validation

## Test Environment
- Go Version: 1.21.x
- Operating System: Linux/macOS/Windows
- Claude Code Version: x.x.x
- TMDB API Key: Valid
- Test Date: YYYY-MM-DD

## Scenario 1: 智能文件重命名
### User Prompt
"帮我查询电影 'Inception' 的详细信息,用于文件重命名"

### Tool Calls Sequence
1. search(query="Inception")
2. get_details(media_type="movie", id=27205)

### Response Time
- Total: 8.5s
- LLM Inference: ~6s
- Tool Calls: ~2.5s

### User Experience Score
- Reply Usefulness: 5/5
- Tool Selection Accuracy: 5/5
- Data Completeness: 5/5
- Overall: 5/5

### Screenshot
[截图或日志片段]

### Notes
Claude 准确理解了用户意图,工具选择正确...

## Scenario 2: 片荒推荐
...

## Performance Summary
| Scenario | Response Time | Performance Goal | Status |
|----------|--------------|------------------|--------|
| 场景 1   | 8.5s         | < 10s            | ✅     |
| 场景 2   | 7.2s         | < 10s            | ✅     |
...

## User Experience Summary
- 总体评分: 4.5/5
- 亮点: Claude 工具选择准确,回复自然有用
- 痛点: 复杂查询偶尔需要澄清

## Error Recovery Tests
...

## Issues Identified
### Blocking Issues
*无*

### Recommendations
1. 考虑添加缓存以提升响应速度
2. 改进某些工具的描述以提高 Claude 选择准确性
...
```

### 编码标准

**本 Story 不涉及编码**,主要是手动测试和文档编写。

**文档编写标准**:
- 使用 Markdown 格式
- 截图使用 PNG 格式
- 日志使用代码块 \`\`\`
- 表格格式清晰
- 所有场景都要记录完整信息

[Source: docs/architecture/coding-standards.md]

## Testing

### 测试方法
本 Story 采用**手动 E2E 测试**,使用真实的 Claude Code 客户端。

### 测试环境
- **TMDB MCP 服务**: 编译后的二进制文件,stdio 模式
- **Claude Code 客户端**: 配置了 tmdb-mcp 服务
- **TMDB API**: 使用真实 TMDB API
- **测试数据**: 真实 TMDB 数据

### 测试范围
- 4 个核心场景(AC 1)
- 2 个额外组合场景(AC 2)
- 性能验证(AC 3)
- 用户体验评分(AC 4)
- 错误恢复测试(AC 5)

### 测试标准
- **响应时间**: 简单场景 < 10s,复杂场景 < 15s
- **用户体验**: 平均评分 ≥ 4.0/5.0
- **错误处理**: 所有错误场景都有友好处理
- **工具选择**: Claude 工具选择准确率 ≥ 90%

### 测试交付物
- `.ai/epic3-e2e-scenarios.md` 文档
- 截图和日志片段
- 性能数据表格
- 用户体验评分
- 问题列表和改进建议

[Source: docs/architecture/test-strategy-and-standards.md#End-to-End Tests]

## Change Log

| Date       | Version | Description  | Author             |
| ---------- | ------- | ------------ | ------------------ |
| 2025-10-16 | 1.0     | 初始故事创建 | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used

*待开发者记录*

### Debug Log References

*待开发者记录*

### Completion Notes

*待开发者记录*

### File List

*待开发者记录*

## QA Results

*待 QA Agent 审查后填写*
